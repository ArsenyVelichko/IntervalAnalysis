\section{Теория}
\subsection{Информационное множество}
Информационным множеством задачи восстановления зависимостей в нашем случае будем называть
\begin{equation}
    \Omega=\{\beta\in\mathbb{R}^2\;|\;X\beta\in\mathbf{y}\}, \;\; \text{где}\; X=
    \begin{pmatrix}
x_1  &  1 \\
x_2  & 1 \\
\vdots & \vdots \\
x_n  &  1
\end{pmatrix}
\end{equation}
\subsection{Коридор совместных значений}
Пусть в задаче восстановления зависимостей информационное множество $\Omega$ параметров зависимостей $y=f(x,\beta)$ совместных с данными является непустым. \textit{Коридором совместных значений} рассматриваемой задачи называется многозначное отображение $\Upsilon$, сопоставляющее каждому значению аргумента $x$ множество
\begin{equation}
    \Upsilon(x)=\bigcup_{\beta\in\Omega}f(x,\beta)
\end{equation}
\subsection{Точечные оценки}
Центр наибольшей диагонали информационного множества
\begin{equation}
    \hat{\theta}_{\mathrm{maxdiag}} = 0.5(b_1 + b_2)
\end{equation}
Центр тяжести информационного множества
\begin{equation}
    \hat{\theta}_{\mathrm{gravity}} = \frac{1}{N} \sum_{i=1}^N b_i
\end{equation}
В вышеприведённых оценках оценках $b_i$ - $i$-ая вершина информационного множества, а $N$ - общее кол-во вершин.\\
Оценка метода наименьших квадратов - решение точечной задачи, составленной из центров интервалов, методом наименьших квадратов.
\subsection{Граничны измерения}
\textit{Граничными} называют измерения, определяющие какой-либо фрагмент границы информационного множества.\\
Подмножество всех граничных измерений в выборке $S_n$ играет особую роль, посколько оно является \textit{минимальной подвыборкой, полностью определяющей модель}. 